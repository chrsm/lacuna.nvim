import "lsqlite3" as sqlite
import "xmlua" as xmlua

import "lacuna.parser.base" as Base

class Go extends Base
  new: (db_path) =>
    @db = sqlite.open db_path

  run_query: (v) =>
    gots = {}
    for r in @db\rows (@@query\gsub "<QUERY_VALUE>", v)
      gots[] = {
        name: r[1]
        type: r[2]
        path: @\strip_frag @\strip_dash_meta r[3]
        frag: @\get_frag r[3]
      }

    print vim.inspect gots
    gots

  get: (file, entries) =>
    -- TODO: remove
    -- i'm assuming other doc sets don't always have the same file,
    -- so it'd be nice to pre-group entries by target file
    -- but i'm not doing that yet
    unless entries[1]
      entries = { entries }

    print "lacuna-go: parse #{ file }"

    fp, err = io.open file
    if err
      error "couldn't parse manual: #{ err }"

    doc = fp\read "*a"
      |> xmlua.HTML.parse

    -- wow, now i get why people just embed a fucking browser.
    -- basically, read up until the next hr, h2, or h3. /shrug
    ret = {}
    for i, v in ipairs entries
      c = {}
      for i, v in ipairs doc\search "//a[@name='#{ v.frag }']"
        -- get next until details/example
        n = v\next!
        while n and n\name! != "details"
          content = n\content!
          for ln in content\gmatch "([^\n]*)\n?"
            c[] = ln

          n = n\next!

      print vim.inspect c
      ret[] =
        name: v.name
        entry: v
        content: c
        search_keys: v.frag

    ret

export default Go
